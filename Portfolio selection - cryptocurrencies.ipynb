{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "import emcee\n",
    "from matplotlib import pyplot as plt\n",
    "import corner\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The stated purpose of this notebook is to explore some cryptocurrency data. Yahoo! doesn't seem to allow programmatic access to its financial data, including crypto data. I felt that scraping data is outside of the scope of this project and so I opted to use a [different API](https://cryptocompare.com) which provides similar data, instead.\n",
    "\n",
    "We begin by exploring the API a little bit. We then request extensive historical price data on several cryptocurrencies. After briefly analyzing some of the summary statistics of the data, we begin to work on a predictive model of asset returns, concluding with an application to portfolio choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://min-api.cryptocompare.com/data/\"\n",
    "api_key = \"f42555b48bbf03e7f64fdbfde60ebe62905fd2103ec9beada0969c3d81c749a8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_url(meth, params):\n",
    "    params[\"api_key\"] = api_key\n",
    "    \n",
    "    return endpoint + meth + \"?\" + \"&\".join([\"{}={}\".format(k, v) for k, v in params.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll request the top 100 crypto symbols by volume, so that we can request the prices of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "meth = \"top/totalvolfull\"\n",
    "params = {}\n",
    "params[\"limit\"] = 100\n",
    "params[\"tsym\"] = \"USD\"\n",
    "\n",
    "ru = req_url(meth, params)\n",
    "data = req.get(ru).json()['Data']\n",
    "top = list(map(lambda c: c['CoinInfo']['Name'], data))\n",
    "n_top = len(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only request 1 crypto symbol at a time. We'll request 3 years of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "meth = \"histoday\"\n",
    "\n",
    "n_top = 10\n",
    "data = {}\n",
    "for i in range(n_top):\n",
    "    params = {}\n",
    "    params[\"fsym\"] = top[i]\n",
    "    params[\"tsym\"] = \"USD\"\n",
    "    params[\"limit\"] = 1 * 365\n",
    "    ru = req_url(meth, params)\n",
    "    data[top[i]] = req.get(ru).json()['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.asarray(list(map(lambda tp: tp['time'], data[\"BTC\"])))[:, np.newaxis]\n",
    "highs = np.asarray(list(map(lambda ticker: list(map(lambda tp: tp[\"high\"], data[ticker])), data.keys()))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.concatenate([times, highs], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"time\"] + top[:n_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>BTC</th>\n",
       "      <th>ETH</th>\n",
       "      <th>EOS</th>\n",
       "      <th>LTC</th>\n",
       "      <th>XRP</th>\n",
       "      <th>ENJ</th>\n",
       "      <th>BCH</th>\n",
       "      <th>QTUM</th>\n",
       "      <th>ZEC</th>\n",
       "      <th>NEO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.520554e+09</td>\n",
       "      <td>9433.38</td>\n",
       "      <td>730.46</td>\n",
       "      <td>6.18</td>\n",
       "      <td>189.98</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>1076.21</td>\n",
       "      <td>19.89</td>\n",
       "      <td>322.04</td>\n",
       "      <td>94.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.520640e+09</td>\n",
       "      <td>9518.62</td>\n",
       "      <td>747.82</td>\n",
       "      <td>6.45</td>\n",
       "      <td>194.73</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>1089.16</td>\n",
       "      <td>19.86</td>\n",
       "      <td>318.14</td>\n",
       "      <td>94.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.520726e+09</td>\n",
       "      <td>9735.64</td>\n",
       "      <td>735.01</td>\n",
       "      <td>6.20</td>\n",
       "      <td>193.19</td>\n",
       "      <td>0.8301</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>1157.26</td>\n",
       "      <td>19.56</td>\n",
       "      <td>318.91</td>\n",
       "      <td>92.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.520813e+09</td>\n",
       "      <td>9907.41</td>\n",
       "      <td>739.87</td>\n",
       "      <td>6.18</td>\n",
       "      <td>193.04</td>\n",
       "      <td>0.8282</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>1150.22</td>\n",
       "      <td>19.39</td>\n",
       "      <td>314.25</td>\n",
       "      <td>92.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.520899e+09</td>\n",
       "      <td>9486.12</td>\n",
       "      <td>714.19</td>\n",
       "      <td>5.94</td>\n",
       "      <td>181.94</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>1099.83</td>\n",
       "      <td>23.15</td>\n",
       "      <td>302.23</td>\n",
       "      <td>88.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time      BTC     ETH   EOS     LTC     XRP     ENJ      BCH  \\\n",
       "0  1.520554e+09  9433.38  730.46  6.18  189.98  0.8415  0.1646  1076.21   \n",
       "1  1.520640e+09  9518.62  747.82  6.45  194.73  0.8412  0.1482  1089.16   \n",
       "2  1.520726e+09  9735.64  735.01  6.20  193.19  0.8301  0.1468  1157.26   \n",
       "3  1.520813e+09  9907.41  739.87  6.18  193.04  0.8282  0.1666  1150.22   \n",
       "4  1.520899e+09  9486.12  714.19  5.94  181.94  0.7991  0.1414  1099.83   \n",
       "\n",
       "    QTUM     ZEC    NEO  \n",
       "0  19.89  322.04  94.10  \n",
       "1  19.86  318.14  94.48  \n",
       "2  19.56  318.91  92.48  \n",
       "3  19.39  314.25  92.58  \n",
       "4  23.15  302.23  88.42  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r(t) = log(x(t + 1)/x(t)) where x(t) is asset price\n",
    "def returns(x):\n",
    "    T = len(x)\n",
    "    r = np.zeros(T - 1)\n",
    "    for t in range(T - 1):\n",
    "        r[t] = np.log(x[t+1]/x[t])\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = returns(np.asarray(df['BTC']))\n",
    "eth = returns(np.asarray(df['ETH']))\n",
    "eos = returns(np.asarray(df['EOS']))\n",
    "ltc = returns(np.asarray(df['LTC']))\n",
    "xrp = returns(np.asarray(df['XRP']))\n",
    "bch = returns(np.asarray(df['BCH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(btc)\n",
    "plt.xlabel(\"return (BTC)\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(btc)\n",
    "plt.xlabel(\"day\")\n",
    "plt.ylabel(\"return (btc)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "data = np.concatenate((btc[:T, np.newaxis],\n",
    "                       eth[:T, np.newaxis],\n",
    "                       eos[:T, np.newaxis],\n",
    "                       ltc[:T, np.newaxis],\n",
    "                       xrp[:T, np.newaxis],\n",
    "                       bch[:T, np.newaxis]), axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the returns are highly correlated across all 6 cryptocurrencies. This greatly affects things like portfolio choice - how do you make a selection of assets in such a way that you maximize returns while minimizing risk (as measured by volatility)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "currencies = ['BTC', 'ETH', 'EOS', 'LTC', 'XRP', 'BCH']\n",
    "\n",
    "cor = np.corrcoef(data)\n",
    "print(cor)\n",
    "plt.imshow(cor)\n",
    "plt.xticks(range(len(currencies)), currencies)\n",
    "plt.yticks(range(len(currencies)), currencies)\n",
    "plt.title(\"Correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Our goal is to build a predictive model for portfolio choice. Formally:\n",
    "\n",
    "Let $\\mathbf{r}(t) \\in \\mathbb{R}^n$ be the return of each of $n$ assets at time $t$, where $r_i(t) = \\log{\\frac{x_i(t + 1)}{x_i(t)}}$ for $i = 1, \\dots, n$. Define the asset covariance matrix as in the econometrics literature as $\\Sigma(t) = \\mathbf{r}(t) \\mathbf{r}(t)^T \\in \\mathbb{R}^{n \\times n}$. Let our training data be $\\{ \\mathbf{r}(t) | t \\in 1, \\dots, T \\}$ where $T$ is the number of training timepoints. Our goal is to define a model capable of then predicting $r(T + 1)$ and $\\Sigma(T + 1)$. We can then optimize portfolio choice by maximizing the Sharpe ratio:\n",
    "\n",
    "$$\\frac{\\mathbf{w}^T \\mathbf{r}(T + 1)}{\\sqrt{\\mathbf{w}^T \\Sigma(T + 1) \\mathbf{w}}}$$\n",
    "\n",
    "where $\\mathbf{w} \\in \\mathbb{S}^{n - 1}$, i.e. $\\mathbf{w}$ is a unit vector.\n",
    "\n",
    "Note that we're being deliberately vague about how we're going to compute $\\mathbf{r}(T + 1)$ and $\\Sigma(T + 1)$ - we'll try a number of different predictive models with the same sort of general idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several possible methods to estimate $\\mathbf{r}(T + 1)$:\n",
    "\n",
    "* Simple regression\n",
    "* Autoregressive models (ARCH, GARCH, ...)\n",
    "* Neural networks (RNNs in particular)\n",
    "* Bayesian methods\n",
    "\n",
    "There are also methods (apparently generally lesser-known outside of econometrics) to estimate $\\Sigma(T + 1)$, including autoregressive models like MGARCH, but these frequently make problematic assumptions.\n",
    "\n",
    "## Proposed model\n",
    "\n",
    "I propose to use the [generalized Wishart process (GWP)](https://www.cs.cmu.edu/~andrewgw/gwp.pdf) to model $\\Sigma(t)$ and a Gaussian process (GP) to model $\\mathbf{r}(t)$. Together, these will produce estimates of $\\mathbf{r}(T + 1)$ and $\\Sigma(T + 1)$ which can then be used for portfolio choice.\n",
    "\n",
    "There are advantages to modelling the price separate from the covariance. For example, consider the Ornstein-Uhlenbeck and squared exponential kernels. The first is great for modeling more volatile data, like currency (real and crypto-). The second is used for more smooth functions. One might assume that while the actual returns follow an O-U Gaussian process, the covariance between currencies is in fact smoother and follows a SE generalized Wishart process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ou(t1, t2, params):\n",
    "    \"\"\"\n",
    "    Ornstein-Uhlenbeck kernel. Commonly used for financial data because\n",
    "    it's not quite as smooth as the squared-exponential kernel.\n",
    "    \"\"\"\n",
    "    tau = params[0]\n",
    "    \n",
    "    return SIG_VAR * np.exp(-abs(t2 - t1)/tau)\n",
    "\n",
    "def squared_exponential(t1, t2, params):\n",
    "    \"\"\"\n",
    "    Squared-exponential kernel.\n",
    "    \"\"\"\n",
    "    tau = params[0]\n",
    "    \n",
    "    return SIG_VAR * np.exp(-((t1 - t2)/tau)**2)\n",
    "\n",
    "def periodic(t1, t2, params):\n",
    "    \"\"\"\n",
    "    A simple periodic kernel function.\n",
    "    \"\"\"\n",
    "    tau = params[0]\n",
    "    \n",
    "    return np.exp(-2*np.sin((t1 - t2)/2)**2/tau**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Gaussian process models, it's important to standardize the data because the kernels we construct are in fact assumed to have diagonally unit variance. This is less important for the GWP model, because any adjustments to the overall scale of the data can be \"absorbed\" into $L$. However, for consistency with our later GP model for predicting $\\mathbf{r}(t)$, we'll proceed with standardization anyway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = np.diag(1/np.sqrt(np.diag(np.cov(data))))\n",
    "data_std = np.matmul(normalizer, data)\n",
    "np.cov(data_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance model\n",
    "\n",
    "The model for $\\Sigma(t)$ follows. It's a direct implementation of equations (15)-(17) and the  sampling procedure described in the GWP paper. We follow their direction and implement [elliptical slice sampling](http://proceedings.mlr.press/v9/murray10a/murray10a.pdf) for sampling the GPs which construct $\\Sigma(t)$. We use the `emcee` library in Python for the Metropolis-Hasting steps (learning $L$ and $\\mathbf{\\theta}$). The main flow of the program is captured in `gibbs_sampler`. I opted not to wrap these methods in a class because it made Jupyter development easier. At the end of this notebook I'll describe how I created and tested the final version of this code (which is in a separate file, with tests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG_VAR = 0.95\n",
    "KERNEL = squared_exponential\n",
    "LOGTHETA_PRIOR_MEAN = 0.5\n",
    "LOGTHETA_PRIOR_VAR = 2\n",
    "L_PRIOR_VAR = 1\n",
    "MH_THETA_SCALE = 1\n",
    "MH_L_SCALE = 1e-1\n",
    "KERNEL_SCALE = 1\n",
    "\n",
    "def kidx(Nu, N, T):\n",
    "    return lambda a, b, c: a * (N * T) + b * T + c\n",
    "\n",
    "def construct_kernel(params, T, k):\n",
    "    \"\"\"\n",
    "    Construct a GP kernel.\n",
    "    \n",
    "    params: The kernel parameters of dimension  x N x h where  is the\n",
    "            d.f., N is the dimensionality of the data, and h is the number\n",
    "            of parameters for the kernel function.\n",
    "    T:      The number of timepoints.\n",
    "    k:      The kernel function.\n",
    "    \n",
    "        Returns a NT x NT kernel matrix.\n",
    "    \"\"\"\n",
    "    Nu, N, h = params.shape\n",
    "    kernel_idx = kidx(Nu, N, T)\n",
    "    \n",
    "    K = np.eye(np.prod([Nu, N, T]))\n",
    "    for nu in range(Nu):\n",
    "        for n in range(N):\n",
    "            for t1 in range(T):\n",
    "                for t2 in range(T):\n",
    "                    i = kernel_idx(nu, n, t1)\n",
    "                    j = kernel_idx(nu, n, t2)\n",
    "                    if t1 != t2:\n",
    "                        K[i, j] = k(t1, t2, params[nu, n, :])\n",
    "    \n",
    "    return K * KERNEL_SCALE\n",
    "\n",
    "def compute_sigma(L, u):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix for a specific timepoint.\n",
    "    \n",
    "    L: The lower cholesky decomposition of the scale parameter for the Wishart\n",
    "       distribution (of dimension N x N).\n",
    "    u: The fitted GP function values that generate the draw from the Wishart distribution.\n",
    "       Dimensionality:  x N.\n",
    "       \n",
    "    Returns the N x N covariance matrix.\n",
    "    \"\"\"\n",
    "    Nu = u.shape[0]\n",
    "    Sig = np.zeros(L.shape)\n",
    "    for nu in range(Nu):\n",
    "        Sig += np.matmul(L, np.matmul(np.outer(u[nu, :], u[nu, :]), L.T))\n",
    "    \n",
    "    return Sig\n",
    "\n",
    "def log_data_likelihood(returns, u, L, Nu):\n",
    "    \"\"\"\n",
    "    The likelihood of the data. We sum over all possible timepoints\n",
    "    $t \\in [T]$, computing the probability using r(t) ~ N(0, (t)).\n",
    "    \"\"\"\n",
    "    loglik = 0\n",
    "    N, T = returns.shape\n",
    "    u = np.reshape(u, (Nu, N, T))\n",
    "    for t in range(T):\n",
    "        Siginv = np.linalg.inv(compute_sigma(L, u[:, :, t]))\n",
    "        term = -0.5*np.matmul(returns[:, t].T, np.matmul(Siginv, returns[:, t]))\n",
    "        loglik += term\n",
    "    \n",
    "    return loglik\n",
    "\n",
    "def init_logtheta(nu, N, h=1):\n",
    "    \"\"\"\n",
    "    Initialize the GP hyperparameters to their logs.\n",
    "    \n",
    "    Returns a  x N x h matrix where each is an independent draw from\n",
    "    the LogNormal prior.\n",
    "    \"\"\"\n",
    "    return np.random.normal(size=(nu, N, h))\n",
    "\n",
    "def init_u(T, theta):\n",
    "    \"\"\"\n",
    "    Initialize the GP draws that will construct the covariance matrix.\n",
    "    \n",
    "    T:     The number of timepoints.\n",
    "    theta: The kernel parameters, of dimension  x N x h where  is the\n",
    "           d.f., N is the dimensionality of the data, and h is the number\n",
    "           of parameters for the kernel function.\n",
    "    \n",
    "    Returns a matrix of dimension  x N x T which is a random draw from\n",
    "    the multivariate normal with kernel constructed by theta.\n",
    "    \"\"\"\n",
    "    N, nu, _ = theta.shape\n",
    "    K = construct_kernel(theta, T, KERNEL)\n",
    "    draw = np.random.multivariate_normal(np.zeros(K.shape[0]), K)\n",
    "    \n",
    "    return draw\n",
    "\n",
    "def init_L(N):\n",
    "    \"\"\"\n",
    "    Initialize the scale parameter for the Wishart distribution.\n",
    "    \n",
    "    Randomly generates a symmetric matrix V, then returns its lower\n",
    "    Cholesky decomposition.\n",
    "    \"\"\"\n",
    "    # X = np.random.randn(N, N)\n",
    "    # V = np.matmul(X, X.T)\n",
    "    # L = np.linalg.cholesky(V)\n",
    "    L = np.eye(N)\n",
    "    \n",
    "    return L * L_PRIOR_VAR\n",
    "\n",
    "def sample_u(f, theta, T, L, nu, returns):\n",
    "    \"\"\"\n",
    "    Sample u (equation 15). We use\n",
    "    [elliptical slice sampling](https://arxiv.org/abs/1001.0175),\n",
    "    specifically a direct implementation of the algorithm in figure 2.\n",
    "    \"\"\"\n",
    "    K = construct_kernel(theta, T, KERNEL)\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    \n",
    "    ellipse = np.random.multivariate_normal(np.zeros(K.shape[0]), K)\n",
    "    u = np.random.uniform()\n",
    "    logy = log_data_likelihood(returns, f, L, nu) + np.log(u)\n",
    "    angle = np.random.uniform(high=2*np.pi)\n",
    "    angle_min, angle_max = angle - 2*np.pi, angle\n",
    "    while True:\n",
    "        fp = f*np.cos(angle) + ellipse*np.sin(angle)\n",
    "        log_data_lik = log_data_likelihood(returns, fp, L, nu)\n",
    "        if log_data_lik > logy:\n",
    "            log_u_lik = -0.5*np.matmul(fp, np.matmul(Kinv, fp))\n",
    "            return fp, log_data_lik + log_u_lik\n",
    "        else:\n",
    "            if angle < 0:\n",
    "                angle_min = angle\n",
    "            else:\n",
    "                angle_max = angle\n",
    "            angle = np.random.uniform(angle_min, angle_max)\n",
    "\n",
    "def sample_logtheta(logtheta, u, T, L, nu, returns):\n",
    "    \"\"\"\n",
    "    Sample theta (equation 16). We use standard M-H as implemented in\n",
    "    emcee to directly sample the next position in the chain.\n",
    "    \"\"\"\n",
    "    def log_logtheta_prob(logthp):\n",
    "        \"\"\"\n",
    "        Computes log(P(u | theta) * P(theta)) directly.\n",
    "        \"\"\"\n",
    "        logthp = np.reshape(logthp, theta.shape)\n",
    "        K = construct_kernel(np.exp(logthp), T, KERNEL)\n",
    "        Kinv = np.linalg.inv(K)\n",
    "        log_u_prob = -0.5*np.matmul(u, np.matmul(Kinv, u))\n",
    "        log_prior = np.sum(\n",
    "            -0.5*((logthp - LOGTHETA_PRIOR_MEAN)**2/LOGTHETA_PRIOR_VAR)\n",
    "        )\n",
    "        \n",
    "        return log_u_prob + log_prior\n",
    "        \n",
    "    dim = np.prod(logtheta.shape)\n",
    "    sampler = emcee.MHSampler(np.eye(dim)*MH_THETA_SCALE, dim=dim, lnprobfn=log_logtheta_prob)\n",
    "    logthetap, _, _ = sampler.run_mcmc(logtheta.flatten(), 1)\n",
    "    \n",
    "    return np.reshape(logthetap, logtheta.shape), log_logtheta_prob(logthetap)\n",
    "\n",
    "def sample_L(L, theta, u, nu, returns):\n",
    "    \"\"\"\n",
    "    Sample L (equation 17). We again use standard M-H as implemented in\n",
    "    emcee.\n",
    "    \"\"\"\n",
    "    def log_L_prob(Lp):\n",
    "        \"\"\"\n",
    "        Computes log(P(returns | u, L) * P(L)).\n",
    "        \"\"\"\n",
    "        Lpm = np.zeros(L.shape)\n",
    "        Lpm[np.tril_indices(L.shape[0])] = Lp\n",
    "        log_prior = np.sum(-0.5*Lp**2/L_PRIOR_VAR)\n",
    "        \n",
    "        return log_data_likelihood(returns, u, Lpm, nu) + log_prior\n",
    "    \n",
    "    dim = int((L.shape[0]**2 + L.shape[0])/2)\n",
    "    sampler = emcee.MHSampler(np.eye(dim)*MH_L_SCALE, dim=dim, lnprobfn=log_L_prob)\n",
    "    Lp, _, _ = sampler.run_mcmc(L[np.tril_indices(L.shape[0])], 1)\n",
    "    Lpm = np.zeros(L.shape)\n",
    "    Lpm[np.tril_indices(L.shape[0])] = Lp\n",
    "    \n",
    "    return Lpm, log_L_prob(Lp)\n",
    "\n",
    "def gibbs_sampler(returns, init=None, numit=1000):\n",
    "    \"\"\"\n",
    "    Perform Gibbs sampling in order to fit the model.\n",
    "    \n",
    "    returns: A matrix of dimension N x T where N is the number of assets\n",
    "             and T is the number of timepoints. Element (n, t) is the\n",
    "             return of the nth asset at time t.\n",
    "    \n",
    "    Returns the chain of samples and diagnostics.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    diagnostics = []\n",
    "    \n",
    "    # Set the hyperparameters\n",
    "    N, T = returns.shape\n",
    "    nu = N + 1\n",
    "    \n",
    "    # Initialize the model parameters\n",
    "    if init:\n",
    "        logtheta = init['logtheta']\n",
    "        u = init['u']\n",
    "        L = init['L']\n",
    "    else:\n",
    "        logtheta = init_logtheta(nu, N)\n",
    "        u = init_u(T, np.exp(logtheta))\n",
    "        logtheta = init_logtheta(nu, N)\n",
    "        L = init_L(N)\n",
    "    \n",
    "    samples.append([u, np.exp(logtheta), L])\n",
    "\n",
    "    # Sample successively. This will converge to draws from\n",
    "    # P(u, theta, L | returns).\n",
    "    for it in range(numit):\n",
    "        data_lik = log_data_likelihood(returns, u, L, nu)\n",
    "        u, u_prob = sample_u(u, np.exp(logtheta), T, L, nu, returns)\n",
    "        logtheta, logtheta_prob = sample_logtheta(logtheta, u, T, L, nu, returns)\n",
    "        L, L_prob = sample_L(L, np.exp(logtheta), u, nu, returns)\n",
    "        if it % 10 is 0:\n",
    "            print(\n",
    "                \"Iteration {}: loglik = {:.2f}, log P(u|...) = {:.2f}, log P(theta|...) = {:.2f}, log P(L|...) = {:.2f}\".format(\n",
    "                    it, data_lik, u_prob, logtheta_prob, L_prob\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        samples.append([u, np.exp(logtheta), L])\n",
    "        diagnostics.append([data_lik, u_prob, logtheta_prob, L_prob])\n",
    "        \n",
    "    return samples, diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples, diagnostics = gibbs_sampler(data_std, numit=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assess model convergence by looking at the data likelihood $P(\\mathcal{D} | L, u, \\theta)$. It's better, however, to look at the posterior over each parameter (e.g. $\\log P(u | \\dots)$). We plot both below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = np.asarray(diagnostics)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for pn in range(4):\n",
    "    plt.subplot(2, 2, pn + 1)\n",
    "    plt.plot(diagnostics[:, pn])\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"log prob\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that convergence occurs after approximately 200 iterations - that is, the first 200 iterations are \"burn-in.\" In theory we can select any sample after that point and it's a valid sample from the posterior $P(u, L, \\theta | \\mathcal{D})$ where $\\mathcal{D}$ is the training data.\n",
    "\n",
    "We can predict according to equation (22) of the GWP paper, and compute $\\Sigma(T + 1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(L, u, theta, Nu, N, T):\n",
    "    Kbinv = np.linalg.inv(construct_kernel(theta, T, KERNEL))\n",
    "    Kfull = construct_kernel(theta, T + 1, KERNEL)\n",
    "    idx = Nu * N * T\n",
    "    A = Kfull[idx:, :idx]\n",
    "    ustar = np.reshape(np.matmul(np.matmul(A, Kbinv), u), (Nu, N, 1))\n",
    "    \n",
    "    return compute_sigma(L, ustar[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(diagnostics[np.argmax(diagnostics[:, 0]), :])\n",
    "top_sample = samples[np.argmax(diagnostics[:, 0])]\n",
    "u, theta, L = top_sample\n",
    "V = np.matmul(L, L.T)\n",
    "print(predict(L, u, theta, 7, 6, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns model\n",
    "\n",
    "We'll now implement a simple algorithm using `emcee` to fit individual GPs to each cryptocurrency's returns. We'll assume each asset's returns are modeled by a zero-mean Gaussian process with an Ornstein-Uhlenbeck kernel. The parameters of the model are the timescales ($\\tau$). We'll assume each asset has its own timescale and signal variance, so we can fit a model for each asset individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_KERNEL = periodic\n",
    "NWALKERS = 100\n",
    "TAU_PRIOR_MEAN = 0.75\n",
    "TAU_PRIOR_VAR = 1\n",
    "SIG_VAR_ALPHA = 10\n",
    "SIG_VAR_BETA = 1.1\n",
    "\n",
    "def construct_kernel_gp(tau, sig_var, T, k):\n",
    "    K = np.eye(T)\n",
    "    for t1 in range(T):\n",
    "        for t2 in range(t1, T):\n",
    "            if t1 != t2:\n",
    "                c = sig_var * k(t1, t2, [tau])\n",
    "                K[t1, t2] = c\n",
    "                K[t2, t1] = c\n",
    "    \n",
    "    return K\n",
    "\n",
    "def fit_gp(returns, numit=1_000):\n",
    "    def log_likelihood(params):\n",
    "        tau, sig_var = params\n",
    "        if tau > 0 and sig_var < 1 and sig_var > 0:\n",
    "            K = construct_kernel_gp(tau, sig_var, len(returns), GP_KERNEL)\n",
    "            Kinv = np.linalg.inv(K)\n",
    "            loglik = -0.5*np.matmul(returns, np.matmul(Kinv, returns))\n",
    "            logtauprior = np.log(1/tau) - 0.5*(np.log(tau) - TAU_PRIOR_MEAN)**2/TAU_PRIOR_VAR\n",
    "            logsigprior = np.log(sig_var**(SIG_VAR_ALPHA - 1)) + np.log((1 - sig_var)**(SIG_VAR_BETA - 1))\n",
    "            \n",
    "            return loglik + logtauprior + logsigprior\n",
    "        else:\n",
    "            return -np.inf\n",
    "    \n",
    "    init = [[np.random.lognormal(0, 1), np.random.uniform(0.87, 0.97)] for _ in range(NWALKERS)]\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(NWALKERS, 2, log_likelihood)\n",
    "    ret = sampler.run_mcmc(init, numit)\n",
    "    \n",
    "    return sampler, ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's fit a GP model on the Bitcoin returns, an examine the corner plots for the two parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler, ret = fit_gp(btc[:50], 500)\n",
    "corner.corner(sampler.chain[:, 100:, :].reshape(-1, 2), labels=[\"$t$\", \"$s$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params = ret[0][np.argmax(ret[1]), :]\n",
    "optimal_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from a GP is straightforward (conditional multivariate normal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gp(prev, k, k_params):\n",
    "    tau, sig_var = k_params\n",
    "    T = len(prev)\n",
    "    K = construct_kernel_gp(tau, sig_var, T + 2, GP_KERNEL)\n",
    "    \n",
    "    return np.matmul(K[:T, T], np.matmul(np.linalg.inv(K[:T, :T]), prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predict_gp(btc[:50], GP_KERNEL, optimal_params)\n",
    "res, btc[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we get an OK prediction (scale might be a bit off, but the direction looks OK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fulfill our goal of a fully automatic portfolio choice algorithm, we need to fit an individual GP to each asset's returns and model the covariance matrix. Now seems like a reasonable time to extract our work from this notebook into actual model classes and write some basic unit tests. We can test the new code here like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = np.loadtxt(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.backtest import backtest_gp, backtest_gwp\n",
    "from model.kernels import squared_exponential, periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting initial models (T = 10)... 0 1 2 3 4 5 \n",
      "[[0.11190342 0.99091117]\n",
      " [0.15645072 0.98539536]\n",
      " [0.12401972 0.97693235]\n",
      " [0.13634843 0.99035475]\n",
      " [0.14853579 0.97711993]\n",
      " [0.12185838 0.99709512]]\n",
      "Fitting models for T = 11...\n",
      "[[0.13331161 0.97540501]\n",
      " [0.13514505 0.99670179]\n",
      " [0.11735181 0.99734226]\n",
      " [0.08384221 0.96195033]\n",
      " [0.1667432  0.98953539]\n",
      " [0.1437692  0.99561209]]\n",
      "Fitting models for T = 12...\n",
      "[[0.11293294 0.98703622]\n",
      " [0.11393554 0.99452595]\n",
      " [0.07803947 0.99281384]\n",
      " [0.10884908 0.9864439 ]\n",
      " [0.15528914 0.97882959]\n",
      " [0.09984786 0.98015901]]\n",
      "Fitting models for T = 13...\n",
      "[[0.086289   0.95487835]\n",
      " [0.12685311 0.99155399]\n",
      " [0.09570407 0.95611467]\n",
      " [0.13449471 0.95633228]\n",
      " [0.13765239 0.97820358]\n",
      " [0.11516465 0.97957087]]\n",
      "Fitting models for T = 14...\n",
      "[[0.11897284 0.98382127]\n",
      " [0.1078423  0.97693938]\n",
      " [0.08793037 0.97454107]\n",
      " [0.09237468 0.99210563]\n",
      " [0.1323896  0.97944454]\n",
      " [0.11006982 0.98000038]]\n"
     ]
    }
   ],
   "source": [
    "gp_pred = backtest_gp(data_std[:, :15], 10, periodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting initial model (T = 10)...\n",
      "Iteration 0: loglik = -9211.41, log P(u|...) = -1868.56, log P(tau|...) = -219.02, log P(L|...) = -1661.66\n",
      "Iteration 10: loglik = -1051.56, log P(u|...) = -1276.52, log P(tau|...) = -236.73, log P(L|...) = -1051.91\n",
      "Iteration 20: loglik = -498.49, log P(u|...) = -703.38, log P(tau|...) = -236.43, log P(L|...) = -480.33\n",
      "Iteration 30: loglik = -405.89, log P(u|...) = -579.42, log P(tau|...) = -235.52, log P(L|...) = -357.28\n",
      "Iteration 40: loglik = -334.64, log P(u|...) = -543.67, log P(tau|...) = -221.80, log P(L|...) = -335.25\n",
      "Iteration 50: loglik = -51.48, log P(u|...) = -263.61, log P(tau|...) = -224.49, log P(L|...) = -56.56\n",
      "Iteration 60: loglik = -45.92, log P(u|...) = -254.83, log P(tau|...) = -221.14, log P(L|...) = -51.13\n",
      "Iteration 70: loglik = -26.66, log P(u|...) = -257.49, log P(tau|...) = -244.19, log P(L|...) = -30.38\n",
      "Iteration 80: loglik = -22.18, log P(u|...) = -250.59, log P(tau|...) = -240.43, log P(L|...) = -27.24\n",
      "Iteration 90: loglik = -21.29, log P(u|...) = -242.27, log P(tau|...) = -232.74, log P(L|...) = -26.62\n",
      "Iteration 100: loglik = -19.54, log P(u|...) = -222.53, log P(tau|...) = -214.84, log P(L|...) = -26.89\n",
      "Iteration 110: loglik = -18.29, log P(u|...) = -229.08, log P(tau|...) = -222.63, log P(L|...) = -28.21\n",
      "Iteration 120: loglik = -13.38, log P(u|...) = -223.08, log P(tau|...) = -220.94, log P(L|...) = -25.48\n",
      "Iteration 130: loglik = -13.78, log P(u|...) = -226.48, log P(tau|...) = -224.57, log P(L|...) = -25.26\n",
      "Iteration 140: loglik = -11.62, log P(u|...) = -219.86, log P(tau|...) = -219.86, log P(L|...) = -23.34\n",
      "Iteration 150: loglik = -12.70, log P(u|...) = -225.42, log P(tau|...) = -224.30, log P(L|...) = -24.47\n",
      "Iteration 160: loglik = -12.00, log P(u|...) = -226.49, log P(tau|...) = -225.77, log P(L|...) = -24.06\n",
      "Iteration 170: loglik = -12.85, log P(u|...) = -221.02, log P(tau|...) = -221.56, log P(L|...) = -23.06\n",
      "Iteration 180: loglik = -11.36, log P(u|...) = -225.72, log P(tau|...) = -226.14, log P(L|...) = -23.17\n",
      "Iteration 190: loglik = -11.61, log P(u|...) = -225.03, log P(tau|...) = -224.75, log P(L|...) = -23.87\n",
      "Iteration 200: loglik = -13.69, log P(u|...) = -226.64, log P(tau|...) = -223.55, log P(L|...) = -26.43\n",
      "Iteration 210: loglik = -17.45, log P(u|...) = -212.75, log P(tau|...) = -205.96, log P(L|...) = -30.13\n",
      "Iteration 220: loglik = -12.06, log P(u|...) = -214.02, log P(tau|...) = -215.38, log P(L|...) = -27.54\n",
      "Iteration 230: loglik = -9.34, log P(u|...) = -205.45, log P(tau|...) = -208.29, log P(L|...) = -26.06\n",
      "Iteration 240: loglik = -11.46, log P(u|...) = -202.46, log P(tau|...) = -202.73, log P(L|...) = -28.64\n",
      "Iteration 250: loglik = -13.18, log P(u|...) = -201.28, log P(tau|...) = -200.89, log P(L|...) = -30.05\n",
      "Iteration 260: loglik = -10.64, log P(u|...) = -209.97, log P(tau|...) = -211.96, log P(L|...) = -27.67\n",
      "Iteration 270: loglik = -11.04, log P(u|...) = -217.11, log P(tau|...) = -216.86, log P(L|...) = -30.47\n",
      "Iteration 280: loglik = -12.29, log P(u|...) = -222.47, log P(tau|...) = -222.09, log P(L|...) = -30.61\n",
      "Iteration 290: loglik = -7.90, log P(u|...) = -221.14, log P(tau|...) = -225.41, log P(L|...) = -24.83\n",
      "Iteration 300: loglik = -8.43, log P(u|...) = -224.40, log P(tau|...) = -227.36, log P(L|...) = -26.14\n",
      "Iteration 310: loglik = -10.01, log P(u|...) = -220.80, log P(tau|...) = -222.17, log P(L|...) = -27.57\n",
      "Iteration 320: loglik = -11.86, log P(u|...) = -199.85, log P(tau|...) = -199.86, log P(L|...) = -28.93\n",
      "Iteration 330: loglik = -14.22, log P(u|...) = -208.22, log P(tau|...) = -208.50, log P(L|...) = -31.09\n",
      "Iteration 340: loglik = -13.74, log P(u|...) = -201.92, log P(tau|...) = -203.35, log P(L|...) = -29.94\n",
      "Iteration 350: loglik = -13.86, log P(u|...) = -221.91, log P(tau|...) = -224.18, log P(L|...) = -28.77\n",
      "Iteration 360: loglik = -11.70, log P(u|...) = -214.08, log P(tau|...) = -218.56, log P(L|...) = -28.25\n",
      "Iteration 370: loglik = -9.35, log P(u|...) = -208.24, log P(tau|...) = -214.06, log P(L|...) = -26.90\n",
      "Iteration 380: loglik = -10.97, log P(u|...) = -209.18, log P(tau|...) = -213.66, log P(L|...) = -28.43\n",
      "Iteration 390: loglik = -12.41, log P(u|...) = -201.89, log P(tau|...) = -201.42, log P(L|...) = -32.22\n",
      "Iteration 400: loglik = -7.97, log P(u|...) = -203.74, log P(tau|...) = -211.20, log P(L|...) = -26.90\n",
      "Iteration 410: loglik = -10.45, log P(u|...) = -197.85, log P(tau|...) = -201.91, log P(L|...) = -31.07\n",
      "Iteration 420: loglik = -9.77, log P(u|...) = -194.03, log P(tau|...) = -199.90, log P(L|...) = -27.12\n",
      "Iteration 430: loglik = -9.76, log P(u|...) = -185.89, log P(tau|...) = -193.30, log P(L|...) = -27.48\n",
      "Iteration 440: loglik = -8.48, log P(u|...) = -193.14, log P(tau|...) = -201.73, log P(L|...) = -26.68\n",
      "Iteration 450: loglik = -11.06, log P(u|...) = -212.31, log P(tau|...) = -218.85, log P(L|...) = -31.60\n",
      "Iteration 460: loglik = -10.86, log P(u|...) = -189.24, log P(tau|...) = -196.16, log P(L|...) = -29.40\n",
      "Iteration 470: loglik = -11.35, log P(u|...) = -194.22, log P(tau|...) = -198.79, log P(L|...) = -29.92\n",
      "Iteration 480: loglik = -13.68, log P(u|...) = -197.47, log P(tau|...) = -201.01, log P(L|...) = -30.55\n",
      "Iteration 490: loglik = -12.21, log P(u|...) = -205.02, log P(tau|...) = -209.66, log P(L|...) = -29.46\n",
      "(462, 462)\n",
      "(420, 420)\n",
      "(42, 420)\n",
      "147\n",
      "Fitting models for T = 11...\n",
      "(462, 462)\n",
      "(420, 420)\n",
      "(42, 420)\n",
      "147\n",
      "Iteration 0: loglik = -233.96, log P(u|...) = -281.29, log P(tau|...) = -270.86, log P(L|...) = -40.87\n",
      "Iteration 10: loglik = -12.77, log P(u|...) = -273.07, log P(tau|...) = -270.91, log P(L|...) = -41.61\n",
      "Iteration 20: loglik = -9.26, log P(u|...) = -263.87, log P(tau|...) = -266.13, log P(L|...) = -38.11\n",
      "Iteration 30: loglik = -9.07, log P(u|...) = -245.75, log P(tau|...) = -248.24, log P(L|...) = -36.95\n",
      "Iteration 40: loglik = -6.15, log P(u|...) = -254.47, log P(tau|...) = -259.95, log P(L|...) = -37.42\n",
      "Iteration 50: loglik = -9.84, log P(u|...) = -235.84, log P(tau|...) = -235.91, log P(L|...) = -40.66\n",
      "Iteration 60: loglik = -6.52, log P(u|...) = -203.47, log P(tau|...) = -209.23, log P(L|...) = -38.86\n",
      "Iteration 70: loglik = -4.74, log P(u|...) = -215.83, log P(tau|...) = -222.96, log P(L|...) = -34.35\n",
      "Iteration 80: loglik = -6.06, log P(u|...) = -209.58, log P(tau|...) = -215.38, log P(L|...) = -35.68\n",
      "Iteration 90: loglik = -8.68, log P(u|...) = -207.63, log P(tau|...) = -210.66, log P(L|...) = -40.01\n",
      "Iteration 100: loglik = -7.83, log P(u|...) = -225.58, log P(tau|...) = -230.08, log P(L|...) = -37.96\n",
      "Iteration 110: loglik = -8.58, log P(u|...) = -228.31, log P(tau|...) = -231.51, log P(L|...) = -36.35\n",
      "Iteration 120: loglik = -9.37, log P(u|...) = -224.84, log P(tau|...) = -227.63, log P(L|...) = -33.24\n",
      "Iteration 130: loglik = -8.95, log P(u|...) = -218.10, log P(tau|...) = -221.19, log P(L|...) = -32.40\n",
      "Iteration 140: loglik = -7.89, log P(u|...) = -220.01, log P(tau|...) = -223.94, log P(L|...) = -31.56\n",
      "Iteration 150: loglik = -12.89, log P(u|...) = -227.58, log P(tau|...) = -227.81, log P(L|...) = -32.14\n",
      "Iteration 160: loglik = -10.67, log P(u|...) = -230.66, log P(tau|...) = -231.81, log P(L|...) = -33.15\n",
      "Iteration 170: loglik = -7.37, log P(u|...) = -229.24, log P(tau|...) = -233.67, log P(L|...) = -34.60\n",
      "Iteration 180: loglik = -7.09, log P(u|...) = -229.21, log P(tau|...) = -238.17, log P(L|...) = -35.64\n",
      "Iteration 190: loglik = -8.33, log P(u|...) = -231.20, log P(tau|...) = -240.09, log P(L|...) = -32.86\n",
      "Iteration 200: loglik = -11.49, log P(u|...) = -230.90, log P(tau|...) = -235.63, log P(L|...) = -33.77\n",
      "Iteration 210: loglik = -9.02, log P(u|...) = -222.04, log P(tau|...) = -227.47, log P(L|...) = -35.95\n",
      "Iteration 220: loglik = -13.16, log P(u|...) = -211.41, log P(tau|...) = -214.93, log P(L|...) = -33.64\n",
      "Iteration 230: loglik = -13.80, log P(u|...) = -210.50, log P(tau|...) = -214.14, log P(L|...) = -34.78\n",
      "Iteration 240: loglik = -12.25, log P(u|...) = -206.51, log P(tau|...) = -210.64, log P(L|...) = -37.56\n",
      "(504, 504)\n",
      "(462, 462)\n",
      "(42, 462)\n",
      "126\n",
      "Fitting models for T = 12...\n",
      "(504, 504)\n",
      "(462, 462)\n",
      "(42, 462)\n",
      "126\n",
      "Iteration 0: loglik = -114.41, log P(u|...) = -308.11, log P(tau|...) = -277.83, log P(L|...) = -58.14\n",
      "Iteration 10: loglik = -17.24, log P(u|...) = -298.41, log P(tau|...) = -293.54, log P(L|...) = -47.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20: loglik = -14.49, log P(u|...) = -290.67, log P(tau|...) = -288.59, log P(L|...) = -44.43\n",
      "Iteration 30: loglik = -8.76, log P(u|...) = -260.11, log P(tau|...) = -263.41, log P(L|...) = -39.93\n",
      "Iteration 40: loglik = -9.59, log P(u|...) = -238.76, log P(tau|...) = -241.06, log P(L|...) = -41.17\n",
      "Iteration 50: loglik = -10.93, log P(u|...) = -236.14, log P(tau|...) = -237.65, log P(L|...) = -44.17\n",
      "Iteration 60: loglik = -13.30, log P(u|...) = -237.90, log P(tau|...) = -236.28, log P(L|...) = -48.23\n",
      "Iteration 70: loglik = -10.69, log P(u|...) = -232.51, log P(tau|...) = -233.43, log P(L|...) = -50.90\n",
      "Iteration 80: loglik = -13.05, log P(u|...) = -241.31, log P(tau|...) = -239.96, log P(L|...) = -41.52\n",
      "Iteration 90: loglik = -9.79, log P(u|...) = -230.14, log P(tau|...) = -232.22, log P(L|...) = -31.36\n",
      "Iteration 100: loglik = -7.07, log P(u|...) = -229.72, log P(tau|...) = -234.46, log P(L|...) = -30.61\n",
      "Iteration 110: loglik = -9.58, log P(u|...) = -226.80, log P(tau|...) = -228.93, log P(L|...) = -33.63\n",
      "Iteration 120: loglik = -13.15, log P(u|...) = -224.77, log P(tau|...) = -224.18, log P(L|...) = -35.52\n",
      "Iteration 130: loglik = -15.63, log P(u|...) = -234.85, log P(tau|...) = -231.02, log P(L|...) = -37.48\n",
      "Iteration 140: loglik = -10.69, log P(u|...) = -244.10, log P(tau|...) = -247.25, log P(L|...) = -34.34\n",
      "Iteration 150: loglik = -10.68, log P(u|...) = -235.69, log P(tau|...) = -243.10, log P(L|...) = -32.04\n",
      "Iteration 160: loglik = -18.03, log P(u|...) = -237.72, log P(tau|...) = -237.64, log P(L|...) = -34.90\n",
      "Iteration 170: loglik = -14.48, log P(u|...) = -233.74, log P(tau|...) = -237.61, log P(L|...) = -33.32\n",
      "Iteration 180: loglik = -18.32, log P(u|...) = -244.98, log P(tau|...) = -247.33, log P(L|...) = -33.76\n",
      "Iteration 190: loglik = -12.96, log P(u|...) = -252.24, log P(tau|...) = -257.60, log P(L|...) = -30.51\n",
      "Iteration 200: loglik = -9.74, log P(u|...) = -247.11, log P(tau|...) = -255.75, log P(L|...) = -29.70\n",
      "Iteration 210: loglik = -10.08, log P(u|...) = -246.74, log P(tau|...) = -254.76, log P(L|...) = -28.50\n",
      "Iteration 220: loglik = -10.01, log P(u|...) = -240.64, log P(tau|...) = -248.12, log P(L|...) = -28.78\n",
      "Iteration 230: loglik = -11.89, log P(u|...) = -234.01, log P(tau|...) = -240.25, log P(L|...) = -30.36\n",
      "Iteration 240: loglik = -11.97, log P(u|...) = -227.60, log P(tau|...) = -232.24, log P(L|...) = -31.95\n",
      "(546, 546)\n",
      "(504, 504)\n",
      "(42, 504)\n",
      "189\n",
      "Fitting models for T = 13...\n",
      "(546, 546)\n",
      "(504, 504)\n",
      "(42, 504)\n",
      "189\n",
      "Iteration 0: loglik = -38.52, log P(u|...) = -347.03, log P(tau|...) = -322.85, log P(L|...) = -58.73\n",
      "Iteration 10: loglik = -18.73, log P(u|...) = -234.39, log P(tau|...) = -228.07, log P(L|...) = -44.02\n",
      "Iteration 20: loglik = -13.79, log P(u|...) = -262.24, log P(tau|...) = -260.07, log P(L|...) = -42.49\n",
      "Iteration 30: loglik = -10.91, log P(u|...) = -260.46, log P(tau|...) = -262.05, log P(L|...) = -36.40\n",
      "Iteration 40: loglik = -10.36, log P(u|...) = -274.54, log P(tau|...) = -276.44, log P(L|...) = -36.07\n",
      "Iteration 50: loglik = -12.51, log P(u|...) = -266.74, log P(tau|...) = -265.74, log P(L|...) = -43.14\n",
      "Iteration 60: loglik = -11.19, log P(u|...) = -273.04, log P(tau|...) = -273.72, log P(L|...) = -37.88\n",
      "Iteration 70: loglik = -10.56, log P(u|...) = -262.90, log P(tau|...) = -267.26, log P(L|...) = -37.05\n",
      "Iteration 80: loglik = -11.12, log P(u|...) = -257.39, log P(tau|...) = -261.08, log P(L|...) = -35.31\n",
      "Iteration 90: loglik = -12.59, log P(u|...) = -254.81, log P(tau|...) = -256.66, log P(L|...) = -33.83\n",
      "Iteration 100: loglik = -10.67, log P(u|...) = -238.76, log P(tau|...) = -243.10, log P(L|...) = -32.00\n",
      "Iteration 110: loglik = -14.32, log P(u|...) = -252.78, log P(tau|...) = -253.23, log P(L|...) = -31.96\n",
      "Iteration 120: loglik = -12.90, log P(u|...) = -256.42, log P(tau|...) = -258.34, log P(L|...) = -32.57\n",
      "Iteration 130: loglik = -13.08, log P(u|...) = -257.06, log P(tau|...) = -257.46, log P(L|...) = -33.69\n",
      "Iteration 140: loglik = -11.19, log P(u|...) = -246.41, log P(tau|...) = -250.05, log P(L|...) = -32.97\n",
      "Iteration 150: loglik = -11.64, log P(u|...) = -262.41, log P(tau|...) = -265.12, log P(L|...) = -33.91\n",
      "Iteration 160: loglik = -8.70, log P(u|...) = -268.77, log P(tau|...) = -275.04, log P(L|...) = -36.55\n",
      "Iteration 170: loglik = -7.89, log P(u|...) = -261.56, log P(tau|...) = -268.58, log P(L|...) = -40.41\n",
      "Iteration 180: loglik = -7.99, log P(u|...) = -260.15, log P(tau|...) = -266.75, log P(L|...) = -41.86\n",
      "Iteration 190: loglik = -13.42, log P(u|...) = -247.70, log P(tau|...) = -255.28, log P(L|...) = -43.93\n",
      "Iteration 200: loglik = -9.56, log P(u|...) = -243.52, log P(tau|...) = -254.87, log P(L|...) = -40.38\n",
      "Iteration 210: loglik = -11.89, log P(u|...) = -240.03, log P(tau|...) = -249.32, log P(L|...) = -40.67\n",
      "Iteration 220: loglik = -13.53, log P(u|...) = -250.29, log P(tau|...) = -257.85, log P(L|...) = -39.92\n",
      "Iteration 230: loglik = -15.00, log P(u|...) = -247.02, log P(tau|...) = -253.07, log P(L|...) = -39.65\n",
      "Iteration 240: loglik = -16.29, log P(u|...) = -238.46, log P(tau|...) = -252.19, log P(L|...) = -39.22\n",
      "(588, 588)\n",
      "(546, 546)\n",
      "(42, 546)\n",
      "168\n",
      "Fitting models for T = 14...\n",
      "(588, 588)\n",
      "(546, 546)\n",
      "(42, 546)\n",
      "168\n",
      "Iteration 0: loglik = -31.68, log P(u|...) = -408.10, log P(tau|...) = -395.59, log P(L|...) = -60.98\n",
      "Iteration 10: loglik = -21.27, log P(u|...) = -390.00, log P(tau|...) = -383.21, log P(L|...) = -50.26\n",
      "Iteration 20: loglik = -17.29, log P(u|...) = -355.05, log P(tau|...) = -349.60, log P(L|...) = -49.02\n",
      "Iteration 30: loglik = -11.88, log P(u|...) = -328.84, log P(tau|...) = -330.33, log P(L|...) = -42.31\n",
      "Iteration 40: loglik = -14.58, log P(u|...) = -321.01, log P(tau|...) = -320.02, log P(L|...) = -44.79\n",
      "Iteration 50: loglik = -10.44, log P(u|...) = -299.84, log P(tau|...) = -302.94, log P(L|...) = -40.72\n",
      "Iteration 60: loglik = -20.17, log P(u|...) = -283.51, log P(tau|...) = -282.99, log P(L|...) = -41.51\n",
      "Iteration 70: loglik = -13.40, log P(u|...) = -263.58, log P(tau|...) = -266.32, log P(L|...) = -37.26\n",
      "Iteration 80: loglik = -14.29, log P(u|...) = -255.23, log P(tau|...) = -255.50, log P(L|...) = -38.37\n",
      "Iteration 90: loglik = -14.69, log P(u|...) = -258.20, log P(tau|...) = -258.28, log P(L|...) = -39.34\n",
      "Iteration 100: loglik = -11.81, log P(u|...) = -276.92, log P(tau|...) = -280.32, log P(L|...) = -36.37\n",
      "Iteration 110: loglik = -11.80, log P(u|...) = -273.56, log P(tau|...) = -273.99, log P(L|...) = -40.41\n",
      "Iteration 120: loglik = -10.35, log P(u|...) = -280.25, log P(tau|...) = -285.05, log P(L|...) = -33.86\n",
      "Iteration 130: loglik = -13.63, log P(u|...) = -280.69, log P(tau|...) = -281.91, log P(L|...) = -36.60\n",
      "Iteration 140: loglik = -9.82, log P(u|...) = -285.97, log P(tau|...) = -290.44, log P(L|...) = -33.35\n",
      "Iteration 150: loglik = -10.24, log P(u|...) = -283.84, log P(tau|...) = -288.64, log P(L|...) = -33.02\n",
      "Iteration 160: loglik = -10.89, log P(u|...) = -281.35, log P(tau|...) = -285.51, log P(L|...) = -33.66\n",
      "Iteration 170: loglik = -11.98, log P(u|...) = -285.36, log P(tau|...) = -287.64, log P(L|...) = -33.78\n",
      "Iteration 180: loglik = -11.51, log P(u|...) = -281.00, log P(tau|...) = -284.22, log P(L|...) = -32.84\n",
      "Iteration 190: loglik = -11.91, log P(u|...) = -276.87, log P(tau|...) = -279.82, log P(L|...) = -33.11\n",
      "Iteration 200: loglik = -15.86, log P(u|...) = -277.11, log P(tau|...) = -276.60, log P(L|...) = -36.57\n",
      "Iteration 210: loglik = -12.11, log P(u|...) = -282.00, log P(tau|...) = -284.80, log P(L|...) = -36.18\n",
      "Iteration 220: loglik = -13.34, log P(u|...) = -284.41, log P(tau|...) = -284.24, log P(L|...) = -34.58\n",
      "Iteration 230: loglik = -12.78, log P(u|...) = -278.70, log P(tau|...) = -278.95, log P(L|...) = -34.16\n",
      "Iteration 240: loglik = -13.69, log P(u|...) = -275.15, log P(tau|...) = -274.66, log P(L|...) = -34.90\n",
      "(630, 630)\n",
      "(588, 588)\n",
      "(42, 588)\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "gwp_pred = backtest_gwp(data_std[:, :15], 10, squared_exponential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now implement the code to maximize the Sharpe ratio. This has a straightforward closed form:\n",
    "\n",
    "$$\\frac{\\Sigma^{-1}\\mathbf{r}}{\\mathbf{1}^T \\Sigma^{-1} \\mathbf{r}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_portfolio(r, cov):\n",
    "    val, vec = np.linalg.eig(cov)\n",
    "    try:\n",
    "        siginv = np.linalg.inv(cov)\n",
    "    except:\n",
    "        cov = np.matmul(vec.T, np.matmul(np.diag(np.real(val - np.min(val))), vec))\n",
    "        siginv = np.linalg.inv(cov)\n",
    "    w = np.matmul(siginv, r) / np.matmul(np.full(len(r), 1), np.matmul(siginv, r))\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And can be called like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10544592, -0.22463318,  0.04758907, -0.15182011, -0.29545119,\n",
       "        1.72976132])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_portfolio(gp_pred[0], gwp_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the hypothetical return on a portfolio selected based on this computation for all of the predicted days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_return(r_pred, sig_pred, data, start_day):\n",
    "    total = 1\n",
    "    for day in range(len(r_pred)):\n",
    "        w = choose_portfolio(r_pred[day], sig_pred[day])\n",
    "        true_return = np.dot(w, np.exp(data[:, start_day + day]))\n",
    "        total *= true_return\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving an overall return of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4155386987000327"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_return(gp_pred, gwp_pred, data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which doesn't look too bad for 5 days of trading. How would it compare to just re-investing returns day over day in BTC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0814041441276252"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(np.exp(data[0, 10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "We built a reasonable model of portfolio choice for cryptocurrency returns. Given more time, there is still much to do:\n",
    "\n",
    "* Compare to a model like MGARCH (easy to do in R)\n",
    "* Improve the speed of the code\n",
    "  - Kernel functions can be implemented in C, or make use of a library like `george`\n",
    "  - Block-diagonal matrix inverses can be sped up in the case of the GWP\n",
    "  - Message-passing implementation to model fitting may be possible\n",
    "* Custom `corner` plots to investigate the relationship between the $\\tau$ parameters and $L$\n",
    "* Live plotting of model fitting\n",
    "* Smarter initialization procedures to speed up convergence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
